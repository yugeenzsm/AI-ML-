{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8CWY/MPeezB66bj2+NVHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yugeenzsm/AI-ML-/blob/main/Workshop5_AIML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avRpt4W1LLRg",
        "outputId": "6d19ca95-e04a-4f6c-f5b9-bb4be020d4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1l6TJeUz4_H-q2x0MSEqjVjzw-Ye_f9tn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R480IwsHLtAK",
        "outputId": "508ce76f-ef7a-4b3e-de49-54f11de7a96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1l6TJeUz4_H-q2x0MSEqjVjzw-Ye_f9tn\n",
            "To: /content/FruitinAmazon.zip\n",
            "\r  0% 0.00/1.24M [00:00<?, ?B/s]\r100% 1.24M/1.24M [00:00<00:00, 76.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip FruitinAmazon.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuxaE64VLxHG",
        "outputId": "49858ad1-45f2-4268-a6ba-1a581dedc55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  FruitinAmazon.zip\n",
            "  inflating: FruitinAmazon/test/cupuacu/download (5).jpeg  \n",
            "  inflating: FruitinAmazon/test/acai/images (2).jpeg  \n",
            "  inflating: FruitinAmazon/test/cupuacu/download (3).jpeg  \n",
            "  inflating: FruitinAmazon/test/acai/images (16).jpeg  \n",
            "  inflating: FruitinAmazon/test/pupunha/download (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (1).jpeg  \n",
            "  inflating: FruitinAmazon/test/cupuacu/download (2).jpeg  \n",
            "  inflating: FruitinAmazon/test/pupunha/download (1).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (4).jpeg  \n",
            "  inflating: FruitinAmazon/test/graviola/download (1).jpeg  \n",
            "  inflating: FruitinAmazon/test/pupunha/download (11).jpeg  \n",
            "  inflating: FruitinAmazon/test/pupunha/download (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (11).jpeg  \n",
            "  inflating: FruitinAmazon/test/tucuma/download (1).jpeg  \n",
            "  inflating: FruitinAmazon/test/acai/images.jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (10).jpeg  \n",
            "  inflating: FruitinAmazon/test/cupuacu/images (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (13).jpeg  \n",
            "  inflating: FruitinAmazon/test/tucuma/download (5).jpeg  \n",
            "  inflating: FruitinAmazon/test/graviola/images (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (7).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (1).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images.jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (15).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (4).jpeg  \n",
            "  inflating: FruitinAmazon/test/cupuacu/download (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (5).jpeg  \n",
            "  inflating: FruitinAmazon/test/acai/download (9).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (5).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (8).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (8).jpeg  \n",
            "  inflating: FruitinAmazon/test/graviola/download (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (9).jpeg  \n",
            "  inflating: FruitinAmazon/test/graviola/download (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (14).jpeg  \n",
            "  inflating: FruitinAmazon/test/guarana/download (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/download.jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (10).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (18).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/download (7).jpeg  \n",
            "  inflating: FruitinAmazon/test/tucuma/download (8).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (9).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (7).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images (8).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (13).jpeg  \n",
            "  inflating: FruitinAmazon/test/tucuma/download (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/download (8).jpeg  \n",
            "  inflating: FruitinAmazon/test/guarana/download (4).jpeg  \n",
            "  inflating: FruitinAmazon/test/pupunha/download (3).jpeg  \n",
            "  inflating: FruitinAmazon/test/guarana/download (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/download (7).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images.jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (7).jpeg  \n",
            "  inflating: FruitinAmazon/test/tucuma/download (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images (1).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/download (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (2).jpeg  \n",
            "  inflating: FruitinAmazon/test/guarana/download (5).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/download (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (10).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (12).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (8).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/download (10).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (1).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images (5).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/download (1).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/download (9).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/download (8).jpeg  \n",
            "  inflating: FruitinAmazon/train/pupunha/images (11).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (6).jpeg  \n",
            "  inflating: FruitinAmazon/test/guarana/images (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/download (5).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images.jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (9).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/download.jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (5).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/download (9).jpeg  \n",
            "  inflating: FruitinAmazon/train/acai/images (12).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (7).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images.jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (5).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/download (3).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (7).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/download.jpeg  \n",
            "  inflating: FruitinAmazon/test/acai/images (17).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (1).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (13).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (12).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/download (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (5).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/images (7).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (6).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (8).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/download (1).jpeg  \n",
            "  inflating: FruitinAmazon/test/graviola/download (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/images (4).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (8).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (1).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (10).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/download (7).jpeg  \n",
            "  inflating: FruitinAmazon/train/guarana/download.jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (2).jpeg  \n",
            "  inflating: FruitinAmazon/train/graviola/images (9).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (11).jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images (9).jpeg  \n",
            "  inflating: FruitinAmazon/train/tucuma/download.jpeg  \n",
            "  inflating: FruitinAmazon/train/cupuacu/images.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Load a sample dataset (MNIST for simplicity)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize and reshape data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")  # 10 classes for MNIST digits\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_test[:5])\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "print(\"Predicted labels:\", predicted_labels)\n",
        "print(\"Actual labels: \", y_test[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7rGo2PvL0CB",
        "outputId": "a625524a-07eb-4d0a-fda9-2341136192cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 34ms/step - accuracy: 0.9080 - loss: 0.2980 - val_accuracy: 0.9831 - val_loss: 0.0490\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 33ms/step - accuracy: 0.9867 - loss: 0.0429 - val_accuracy: 0.9873 - val_loss: 0.0380\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 33ms/step - accuracy: 0.9912 - loss: 0.0281 - val_accuracy: 0.9906 - val_loss: 0.0276\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 33ms/step - accuracy: 0.9936 - loss: 0.0197 - val_accuracy: 0.9889 - val_loss: 0.0315\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 34ms/step - accuracy: 0.9953 - loss: 0.0144 - val_accuracy: 0.9892 - val_loss: 0.0315\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0402\n",
            "Test accuracy: 0.9892\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
            "Predicted labels: [7 2 1 0 4]\n",
            "Actual labels:  [7 2 1 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image  # Import Pillow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define dataset path\n",
        "train_dir = \"/content/FruitinAmazon/train\"\n",
        "test_dir = \"/content/FruitinAmazon/test\"\n",
        "\n",
        "# Get class names (subdirectories)\n",
        "class_names = sorted(os.listdir(train_dir))\n",
        "if not class_names:\n",
        "  print(\"No class directories found in the train folder!\")\n",
        "else:\n",
        "  print(f\"Found {len(class_names)} classes: {class_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LueyrA9TYfR_",
        "outputId": "896d9248-36c1-4494-e1c5-9915d3d98389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6 classes: ['acai', 'cupuacu', 'graviola', 'guarana', 'pupunha', 'tucuma']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define image size and batch size\n",
        "img_height = 128  # Example image height\n",
        "img_width = 128   # Example image width\n",
        "batch_size = 32\n",
        "validation_split = 0.2  # 80% training, 20% validation\n",
        "\n",
        "# Create a preprocessing layer for normalization\n",
        "rescale = tf.keras.layers.Rescaling(1./255)  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Create training dataset with normalization\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',  # Use inferred labels from directory structure\n",
        "    label_mode='int',   # Labels will be integer encoded\n",
        "    image_size=(img_height, img_width),  # Resize images to the specified size\n",
        "    interpolation='nearest',  # Interpolation method\n",
        "    batch_size=batch_size,  # Batch size for training\n",
        "    shuffle=True,  # Shuffle the dataset\n",
        "    validation_split=validation_split,  # Split the dataset for validation\n",
        "    subset='training',  # Specify the subset as training data\n",
        "    seed=123  # Set the seed for reproducibility\n",
        ")\n",
        "\n",
        "# Apply the normalization (Rescaling) to the training dataset\n",
        "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
        "\n",
        "# Create validation dataset with normalization\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',  # Use inferred labels from directory structure\n",
        "    label_mode='int',   # Labels will be integer encoded\n",
        "    image_size=(img_height, img_width),  # Resize images to the specified size\n",
        "    interpolation='nearest',  # Interpolation method\n",
        "    batch_size=batch_size,  # Batch size for validation\n",
        "    shuffle=False,  # Don't shuffle validation data\n",
        "    validation_split=validation_split,  # Split the dataset for validation\n",
        "    subset='validation',  # Specify the subset as validation data\n",
        "    seed=123  # Set the seed for reproducibility\n",
        ")\n",
        "\n",
        "# Apply the normalization (Rescaling) to the validation dataset\n",
        "val_ds = val_ds.map(lambda x, y: (rescale(x), y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsHkCclKZYX_",
        "outputId": "0c76729d-dcf5-4fa7-add4-ef7b1c0c455c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 90 files belonging to 6 classes.\n",
            "Using 72 files for training.\n",
            "Found 90 files belonging to 6 classes.\n",
            "Using 18 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Load a sample dataset (MNIST for simplicity)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize and reshape data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")  # 10 classes for MNIST digits\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_test[:5])\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "print(\"Predicted labels:\", predicted_labels)\n",
        "print(\"Actual labels: \", y_test[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3jEIMqSZgSL",
        "outputId": "8bbed448-e217-45e5-b6c6-a01b028800fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 27ms/step - accuracy: 0.8821 - loss: 0.3655 - val_accuracy: 0.9846 - val_loss: 0.0478\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0547 - val_accuracy: 0.9835 - val_loss: 0.0516\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 25ms/step - accuracy: 0.9887 - loss: 0.0361 - val_accuracy: 0.9872 - val_loss: 0.0380\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 24ms/step - accuracy: 0.9918 - loss: 0.0254 - val_accuracy: 0.9894 - val_loss: 0.0314\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 25ms/step - accuracy: 0.9934 - loss: 0.0205 - val_accuracy: 0.9886 - val_loss: 0.0380\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0482\n",
            "Test accuracy: 0.9886\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "Predicted labels: [7 2 1 0 4]\n",
            "Actual labels:  [7 2 1 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Apply data augmentation to your training data\n",
        "train_ds = datagen.flow_from_directory('train_dir', ...)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Y7q9yzvcnwqb",
        "outputId": "3aef4ad8-c39d-4939-dd92-06ada215f629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'ellipsis' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1044ae0eea23>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Apply data augmentation to your training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         super().set_processing_attrs(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0mimage_data_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mset_processing_attrs\u001b[0;34m(self, image_data_generator, target_size, color_mode, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \"\"\"\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_aspect_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"rgb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rgba\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
          ]
        }
      ]
    }
  ]
}